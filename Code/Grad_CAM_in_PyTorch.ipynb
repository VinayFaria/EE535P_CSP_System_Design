{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grad-CAM in PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "usla2PjoLQEY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Reference: https://medium.com/@stepanulyanin/implementing-grad-cam-in-pytorch-ea0937c31e82\n",
        "\n",
        "Grad-CAM Research paper: https://arxiv.org/pdf/1610.02391.pdf\n",
        "\n",
        "ImageNet classes: https://deeplearning.cms.waikato.ac.nz/user-guide/class-maps/IMAGENET/"
      ],
      "metadata": {
        "id": "CqXfQYZaqLZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "from torchvision.models import vgg19\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "HDiK6_uULCp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset\n",
        "from torchvision.datasets.utils import download_url\n",
        "#dataset_url = \"https://www.bestelectricbikes.com/wp-content/uploads/2021/03/Bike_Brake_Repair_Banner_Photo-1-1024x683.jpg\"\n",
        "#dataset_url = \"https://www.zhsydz.com/wp-content/uploads/2020/01/electric-commuter-bike-1000x500.jpg\"\n",
        "dataset_url = \"https://cdn.britannica.com/q:60/82/212182-050-50D9F3CE/basketball-LeBron-James-Cleveland-Cavaliers-2018.jpg\"\n",
        "data_dir = './data/test_folder/'    # dataset directory\n",
        "download_url(dataset_url, data_dir) "
      ],
      "metadata": {
        "id": "5fzW0kjs730P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img in os.listdir(data_dir):\n",
        "    filename = img\n",
        "image = cv2.imread(os.path.join(data_dir, filename))\n",
        "\n",
        "print('The image', filename, 'is of shape', image.shape)"
      ],
      "metadata": {
        "id": "rnVvYFBpLi47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnSWdiDYqHtF"
      },
      "outputs": [],
      "source": [
        "# use the ImageNet transformation\n",
        "transform = transforms.Compose([transforms.Resize((224, 224)), \n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "# Above mean and standard deviation are of ImageNet datasets.\n",
        "\n",
        "# define a 1 image dataset\n",
        "dataset = ImageFolder('./data/', transform=transform)\n",
        "\n",
        "# define the dataloader to load that single image\n",
        "dataloader = data.DataLoader(dataset=dataset, shuffle=False, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img1, img2 = next(iter(dataloader))\n",
        "dummy = img1[0]\n",
        "plt.imshow(dummy.permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "oaZ4xUqqwIMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = vgg19(pretrained=True)\n",
        "features_conv = vgg.features\n",
        "print(features_conv)\n",
        "max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "classifier = vgg.classifier\n",
        "print(classifier)"
      ],
      "metadata": {
        "id": "m_i183lpBjOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG, self).__init__()\n",
        "        \n",
        "        # get the pretrained VGG19 network\n",
        "        self.vgg = vgg19(pretrained=True)\n",
        "        \n",
        "        # disect the network to access its last convolutional layer\n",
        "        self.features_conv = self.vgg.features[:36]\n",
        "        \n",
        "        # get the max pool of the features stem\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "        \n",
        "        # get the classifier of the vgg19\n",
        "        self.classifier = self.vgg.classifier\n",
        "        \n",
        "        # placeholder for the gradients\n",
        "        self.gradients = None\n",
        "    \n",
        "    # hook for the gradients of the activations\n",
        "    def activations_hook(self, grad):\n",
        "        self.gradients = grad\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.features_conv(x)\n",
        "        \n",
        "        # register the hook\n",
        "        h = x.register_hook(self.activations_hook)\n",
        "        \n",
        "        # apply the remaining pooling\n",
        "        x = self.max_pool(x)\n",
        "        x = x.view((1, -1))\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "    \n",
        "    # method for the gradient extraction\n",
        "    def get_activations_gradient(self):\n",
        "        return self.gradients\n",
        "    \n",
        "    # method for the activation exctraction\n",
        "    def get_activations(self, x):\n",
        "        return self.features_conv(x)"
      ],
      "metadata": {
        "id": "_RVrG2r6qaPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the VGG model\n",
        "vgg = VGG()\n",
        "\n",
        "# set the evaluation mode\n",
        "vgg.eval()\n",
        "\n",
        "# get the image from the dataloader\n",
        "img, _ = next(iter(dataloader))\n",
        "\n",
        "# get the most likely prediction of the model\n",
        "pred = vgg(img)"
      ],
      "metadata": {
        "id": "CxhYAc3cqe_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Below library from \"https://github.com/nottombrown/imagenet-stubs\"\n",
        "import imagenet_stubs\n",
        "from imagenet_stubs.imagenet_2012_labels import label_to_name\n",
        "max_pred_index = torch.argmax(pred)\n",
        "print('Index of predicted class of ImageNet is:', max_pred_index.item(), ',', 'Class name:', label_to_name(max_pred_index.item()))\n",
        "print(pred[0][max_pred_index])"
      ],
      "metadata": {
        "id": "VoBavWYCEkWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the gradient of the output with respect to the parameters of the model\n",
        "pred[:, max_pred_index].backward()"
      ],
      "metadata": {
        "id": "htlE4W-ZDHc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pull the gradients out of the model\n",
        "gradients = vgg.get_activations_gradient()\n",
        "print(gradients.shape)"
      ],
      "metadata": {
        "id": "WTVGCwWIDHG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pool the gradients across the channels\n",
        "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])     # from this we get expression 1 of paper\n",
        "pooled_gradients_shape = list(pooled_gradients.shape)\n",
        "print('number of importance weights:', pooled_gradients_shape[0])"
      ],
      "metadata": {
        "id": "4QXGePeGDMUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the activations of the last convolutional layer\n",
        "activations = vgg.get_activations(img).detach()\n",
        "print('shape of activation map:', activations.shape)"
      ],
      "metadata": {
        "id": "0EqAK5tfDMSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weight the channels by corresponding gradients\n",
        "for i in range(pooled_gradients_shape[0]):\n",
        "    activations[:, i, :, :] *= pooled_gradients[i]"
      ],
      "metadata": {
        "id": "vHIwh-N-DMPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# average the channels of the activations\n",
        "heatmap = torch.mean(activations, dim=1).squeeze()\n",
        "print(heatmap.shape)"
      ],
      "metadata": {
        "id": "Q0f4LqU3QboZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# relu on top of the heatmap\n",
        "heatmap = np.maximum(heatmap, 0)        # from this we get expression 2 of paper"
      ],
      "metadata": {
        "id": "X20D1T8kQd8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the heatmap\n",
        "heatmap /= torch.max(heatmap)"
      ],
      "metadata": {
        "id": "mHQAUnejQdzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# draw the heatmap\n",
        "plt.matshow(heatmap.squeeze())"
      ],
      "metadata": {
        "id": "UlRCXUJvqnrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(os.path.join(folder,filename))\n",
        "heatmap = cv2.resize(heatmap.numpy(), (img.shape[1], img.shape[0]), interpolation= cv2.INTER_LINEAR)\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "superimposed_img = heatmap * 0.4 + img\n",
        "cv2.imwrite('./Grad-CAM_image.jpg', superimposed_img)"
      ],
      "metadata": {
        "id": "2ytg_mFQqqej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "display(Image(os.path.join(folder,filename)))\n",
        "display(Image('./Grad-CAM_image.jpg'))"
      ],
      "metadata": {
        "id": "Eub-D1N6vNds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Operations Example"
      ],
      "metadata": {
        "id": "usla2PjoLQEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[[[-2.,10],[4,40],[6,60],[8,80],[10,100]],\n",
        "                   [[-3,30],[6,60],[9,90],[12,120],[15,150]],\n",
        "                   [[-4,40],[8,80],[12,120],[16,160],[20,200]],\n",
        "                   [[-5,50],[10,100],[15,150],[20,200],[25,250]],\n",
        "                   [[-6,60],[12,120],[18,180],[24,240],[30,300]],\n",
        "                   [[-7,70],[14,140],[21,210],[28,280],[35,350]]]])\n",
        "for i in range(list(a.shape)[0]):\n",
        "    print(a[:, 0, :, :])\n",
        "print(a.shape)\n",
        "b = torch.mean(a, dim=1).squeeze()\n",
        "c = torch.mean(a, dim=1).squeeze()\n",
        "print(b)\n",
        "print(c)\n",
        "b = np.maximum(b, 0)\n",
        "print(b)\n",
        "b /= torch.max(b)\n",
        "print(b)\n",
        "plt.matshow(b.squeeze())\n",
        "\n",
        "d = np.uint8(255 * b)\n",
        "print(d)"
      ],
      "metadata": {
        "id": "5G9BGQ1ELTg-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}